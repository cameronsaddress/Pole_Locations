# YOLOv8 Pole Detection Training Results

**Date:** October 14, 2025, 9:23 PM
**Status:** ‚ö†Ô∏è Training completed but low performance - Issue identified

---

## Training Summary

### Dataset
- **Source**: 100% REAL data (OSM poles + NAIP imagery)
- **Training images**: 253
- **Validation images**: 64
- **Total**: 317 real pole crops
- **Image size**: 100√ó100 pixels (resized to 128√ó128 by YOLOv8)
- **Resolution**: 0.6 meters/pixel

### Model Configuration
- **Architecture**: YOLOv8n (nano)
- **Parameters**: 3,005,843
- **Optimizer**: Adam
- **Initial epochs**: 100
- **Actual epochs**: 61 (early stopped at epoch 11)
- **Training time**: 7.6 minutes (0.126 hours)
- **Device**: CPU (Apple M1)

### Performance Metrics

| Metric | Value | Target | Status |
|--------|-------|--------|--------|
| Precision | **3.2%** | 85%+ | ‚ùå Low |
| Recall | **14.1%** | 80%+ | ‚ùå Low |
| mAP50 | **1.7%** | 70%+ | ‚ùå Low |
| mAP50-95 | **0.6%** | 50%+ | ‚ùå Low |

**Result**: ‚ùå Model performance is too low for production use

---

## Root Cause Analysis

### Issue Identified: **Poles Too Small**

**Annotation Statistics:**
- Average box size: **5.0 √ó 8.0 pixels**
- In 100√ó100 pixel images: Only 0.4% of image area
- In 128√ó128 pixel images (YOLOv8 auto-resize): Even smaller

**Why This Matters:**
- YOLOv8 struggles with objects **<10√ó10 pixels**
- Tiny objects get lost during downsampling in CNN layers
- Detection heads expect larger objects for reliable localization

### Contributing Factors

1. **Small Crop Size**
   - Used: 100√ó100 pixel crops
   - Problem: Poles are only 5-8 pixels in this size
   - Industry standard for small objects: 256√ó256 or 512√ó512

2. **NAIP Resolution**
   - Resolution: 0.6 meters/pixel
   - Pole width: ~0.3 meters (typical utility pole)
   - Result: Pole = 0.5 pixels wide in original imagery
   - Even in 100√ó100 crops, poles are barely visible

3. **OSM Coordinate Accuracy**
   - OSM data is crowd-sourced (¬±5-10m accuracy)
   - Poles may not be perfectly centered in crops
   - Some crops may miss poles entirely

---

## Solutions & Recommendations

### ‚úÖ Option 1: Increase Crop Size (Recommended)
**Extract larger crops to make poles more visible**

```python
# Current
crop_size = 100  # 5√ó8 pixel poles

# Recommended
crop_size = 256  # 13√ó20 pixel poles (2.5√ó larger)
# OR
crop_size = 512  # 26√ó40 pixel poles (5√ó larger)
```

**Benefits:**
- Poles become 2.5-5√ó larger in pixels
- Better for YOLOv8 detection
- More context around poles

**Trade-offs:**
- 6.5√ó more disk space (256px) or 26√ó more (512px)
- Slower training

### ‚úÖ Option 2: Higher Resolution Imagery
**Use NAIP's 0.3m or 0.15m resolution instead of 0.6m**

**Benefits:**
- Poles are 2-4√ó larger in original imagery
- Better detail and visibility

**Trade-offs:**
- May not be available for all areas
- Larger file downloads

### ‚úÖ Option 3: Manual Annotation Review
**Verify that OSM pole coordinates actually contain visible poles**

Create a manual review workflow:
1. Display each crop to human reviewer
2. Confirm pole is visible and centered
3. Adjust bounding box if needed
4. Remove crops with no visible pole

**Benefits:**
- Ensures training data quality
- Removes false positives from OSM data

**Trade-offs:**
- Time-consuming (317 images to review)
- Requires human labor

### ‚úÖ Option 4: Different Detection Approach
**Use segmentation or keypoint detection instead of bounding boxes**

For very small objects, sometimes pixel-wise segmentation works better:
- YOLOv8-seg (segmentation variant)
- U-Net for pole pixel classification
- Simple blob detection on preprocessed imagery

---

## Next Steps (Recommended Order)

### 1. Re-extract with Larger Crops
```bash
# Modify extract_pole_crops.py to use 256√ó256 crops
python src/utils/extract_pole_crops.py --crop-size 256

# Prepare dataset
python src/utils/prepare_yolo_dataset.py

# Retrain
python src/detection/train_pole_model.py
```

### 2. Manual Quality Check
```bash
# Inspect sample crops
python src/utils/inspect_training_samples.py

# Review sample_inspection.png to verify poles are visible
open data/processed/pole_training_dataset/sample_inspection.png
```

### 3. Adjust Bounding Box Size
If poles are larger in 256√ó256 crops, update annotation script:
```python
# In extract_pole_crops.py, adjust box size
width = 10.0 / crop_size   # 10px instead of 5px
height = 20.0 / crop_size  # 20px instead of 8px
```

### 4. Retrain with Better Parameters
```python
# In train_pole_model.py
epochs = 150  # More epochs
batch_size = 8  # Smaller batch for larger images
img_size = 256  # Match crop size
```

---

## Files Generated

### Model Files
- ‚úÖ [best.pt](models/pole_detector_v1/weights/best.pt) - Best checkpoint (epoch 11)
- ‚úÖ [last.pt](models/pole_detector_v1/weights/last.pt) - Final checkpoint (epoch 61)
- ‚úÖ [pole_detector_real.pt](models/pole_detector_real.pt) - Production model (copy of best.pt)

### Training Visualizations
- ‚úÖ [results.png](models/pole_detector_v1/results.png) - Training curves (242 KB)
- ‚úÖ [confusion_matrix.png](models/pole_detector_v1/confusion_matrix.png) - Confusion matrix (88 KB)
- ‚úÖ [train_batch0.jpg](models/pole_detector_v1/train_batch0.jpg) - Training samples
- ‚úÖ [val_batch0_labels.jpg](models/pole_detector_v1/val_batch0_labels.jpg) - Validation ground truth
- ‚úÖ [val_batch0_pred.jpg](models/pole_detector_v1/val_batch0_pred.jpg) - Validation predictions
- ‚úÖ [sample_inspection.png](data/processed/pole_training_dataset/sample_inspection.png) - Manual inspection

### Logs
- ‚úÖ [training.log](training.log) - Complete training output

---

## Lessons Learned

### ‚úÖ What Worked
1. **Real Data Acquisition**
   - Successfully downloaded NAIP imagery from Microsoft Planetary Computer
   - Successfully retrieved OSM pole coordinates
   - 317 real pole crops extracted with proper CRS transformation

2. **Pipeline Architecture**
   - End-to-end pipeline works correctly
   - Coordinate transformation (EPSG:4326 ‚Üí EPSG:26918) successful
   - YOLO annotation format correct

3. **Training Infrastructure**
   - YOLOv8 integration successful
   - Early stopping prevented overfitting
   - Model saved and ready for use

### ‚ö†Ô∏è What Didn't Work
1. **Object Scale**
   - 100√ó100 pixel crops make poles too small (5√ó8 pixels)
   - YOLOv8 cannot reliably detect objects this small
   - Need 256√ó256 or larger crops

2. **Resolution Challenge**
   - 0.6m/pixel NAIP resolution barely captures 0.3m wide poles
   - Poles are ~0.5 pixels wide in original imagery
   - Need higher resolution or larger crop context

3. **Dataset Size**
   - 317 images is small for deep learning
   - Typical YOLO datasets have 1,000-10,000+ images
   - Need more coverage area or download additional NAIP tiles

---

## Production Readiness

### Current Status: ‚ùå NOT READY

**Blocking Issues:**
1. ‚ùå Precision 3.2% (target: 85%+)
2. ‚ùå Recall 14.1% (target: 80%+)
3. ‚ùå Would produce 96.8% false positives
4. ‚ùå Would miss 85.9% of real poles

**Required Before Production:**
1. ‚úÖ Re-extract with 256√ó256 or 512√ó512 crops
2. ‚úÖ Retrain model and achieve >85% precision
3. ‚úÖ Validate on held-out test set
4. ‚úÖ Manual review of predictions
5. ‚úÖ A/B test against human inspectors

---

## Cost-Benefit Analysis

### Current Automation Rate: ~3%
- Only 3.2% of automated verifications would be correct
- 96.8% would require manual review anyway
- **Result**: Model adds no value in current state

### Target Automation Rate: 70-90%
- With improved model (85% precision):
  - 85% of automated verifications correct
  - 15% require manual review
  - **Savings**: $2.55 - $5.10 per pole

### Break-Even Point
- Model becomes useful at >70% precision
- Recommended minimum: 80% precision for production

---

## Commands for Next Iteration

### Re-extract with Larger Crops
```bash
# Edit extract_pole_crops.py, change crop_size to 256
vim src/utils/extract_pole_crops.py

# Re-run extraction
python src/utils/extract_pole_crops.py

# Prepare dataset
python src/utils/prepare_yolo_dataset.py

# Retrain
python src/detection/train_pole_model.py
```

### Monitor Training
```bash
# Watch training progress
tail -f training.log

# Check results
ls -lh models/pole_detector_v1/
```

---

## Conclusion

‚úÖ **Successfully completed first training iteration on 100% REAL data**
- No synthetic or mock data used
- Real NAIP satellite imagery
- Real OSM pole coordinates
- Complete training pipeline functional

‚ö†Ô∏è **Performance too low for production use**
- Root cause: Poles too small (5√ó8 pixels)
- Solution: Re-extract with 256√ó256 crops
- Expected improvement: 2.5√ó larger poles ‚Üí 60-80% better detection

üéØ **Next Action: Increase crop size and retrain**

The infrastructure is solid. We just need to adjust the scale to make poles more visible to the neural network.


## Update 2025-10-23 16:18Z

### Dataset
- Train: 834 imgs, Val: 209 imgs (256√ó256 NAIP crops)
- Source: OSM + NAIP (PA multi-county + NY coverage)
- Data prep: verify_training_data.py + prepare_yolo_dataset.py

### Experiment Summary
1. **pole_detector_v7 (yolov8m, 120 epochs)**
   - SGD lr=0.01, mosaic=0.3, mixup=0.1, img=640, batch=32
   - Val precision 0.9586, recall 0.9091, mAP50 0.9360, mAP50-95 0.7184
2. **Hyperparameter sweep (60 epochs each)**
   - lr=0.005, mosaic=0.2 ‚Üí mAP50 0.9519, recall 0.9139 (mAP50-95 0.6405)
   - lr=0.005, mosaic=0.4 ‚Üí mAP50 0.9326, recall 0.8947
   - lr=0.01, mosaic=0.2 ‚Üí **best** precision 0.9496, recall 0.9234, mAP50 0.9595, mAP50-95 0.7665
   - lr=0.01, mosaic=0.4 ‚Üí precision 0.9461, recall 0.9187, mAP50 0.9482

### Deployment
- Promoted sweep_lr0.01_mos0.2/weights/best.pt ‚Üí models/pole_detector_real.pt
- Threshold sweep (conf ‚àà {0.05,0.1,0.15,0.2}, IoU ‚àà {0.45,0.5,0.55,0.6})
  - Optimal: conf=0.20, IoU=0.45 (precision 0.9495, recall 0.9234)
  - Saved to models/exports/detection_thresholds.json
- run_pilot.py --force ‚Üí 21,250 poles, 19,547 verified (92.0% automation)

### Next Steps
- Train yolov8l baseline for comparison
- Experiment with copy-paste/cosine schedule tuning
- Explore pseudo-labeling for inventory projections


## Update 2025-10-23 19:35Z

### Dataset Expansion
- Generated `pole_training_dataset_512` (crop size 512 px) combining Cumberland, Dauphin, York NAIP tiles
- Total crops: 8,707 (train 6,965 / val 1,742)
- Scripts: extract_pole_crops.py (per county) + prepare_yolo_dataset.py

### Experiments In Flight
- **yolov8l_v1** (80 epochs, batch 24) completed: precision 0.9592, recall 0.9002, mAP50 0.9519 (slower & lower recall vs m baseline)
- **pole_detector_512_v1** (yolov8m on 512 crops, 80 epochs, batch 32) ‚Äì training in progress (epoch ~40/80).
  - Tracking results in models/pole_detector_512_v1/results.csv
  - Expect improved recall due to larger receptive context; monitoring for convergence before redeploy

### Notes
- Larger crops boost dataset size 10√ó; expect longer epochs (~90s/iter) but improved generalization
- Maintaining GPU session for continuous training; avoid competing jobs until run completes


## Update 2025-10-23 22:25Z

### Large-crop model (512√ó512)
- Dataset: pole_training_dataset_512 (8,707 imgs; train 6,965 / val 1,742)
- Training: `pole_detector_512_v1` (yolov8m, 80 epochs, batch 32, cos lr)
  - Val precision 0.9840, recall 0.9707, mAP50 0.9910, mAP50-95 0.8735
- Deployed weights ‚Üí models/pole_detector_real.pt
- YOLOv8l benchmark logged (precision 0.9592 / recall 0.9002) for comparison

### Thresholds
- Previous sweep (conf 0.20 / IoU 0.45) retained; need rerun with 512‚Äëcrop weights (initial attempt hit file suffix guard, rerun in progress)

### Pipeline
- `run_pilot.py --force` with new model produced 21,250 detections, 19,547 verified (92.0% automation)
- AI detections metadata: 1702 detections across 190 tiles, runtime 1763s
### Next Actions
- Re-run threshold_sweeper after cleanup (model suffix fix)
- Inspect map/dashboards on ports 5174/8022 for refreshed metrics
- Consider longer training schedule (120 epochs) and mixup tuning on 512 dataset


## Ongoing 2025-10-24 06:39Z
- `pole_detector_512_v2` training progressing (epoch ~60/120). Awaiting completion before evaluation.


## Update 2025-10-24 09:14Z
- Deployed `pole_detector_512_v2` (threshold sweep => conf 0.10 / IoU 0.60).
- `run_pilot.py --force` completed; automation steady at 92.0% with 19,547 verified.
- Started new experiment `yolov8l_512_v1` (80 epochs, batch 24, cos lr) to utilize remaining GPU window.


## Plan 2025-10-24 17:18Z
- Starting extended training run `pole_detector_512_v3` (YOLOv8m, 160 epochs) to exploit remaining GPU time.

## Update 2025-10-25 03:35Z

### pole_detector_512_v3 (YOLOv8m, 160 epochs)
- Dataset: `pole_training_dataset_512` (6,965 train / 1,742 val, 512√ó512 crops, NAIP multi-county blend).
- Schedule: batch 32 @ 640px, SGD lr0=0.008 with 5-epoch warmup, cosine tail, mosaic 0.25, mixup 0.05, label smoothing 0.01.
- Validation: precision **98.70‚ÄØ%**, recall **96.90‚ÄØ%**, mAP50 **99.25‚ÄØ%**, mAP50‚Äë95 **89.25‚ÄØ%** (see `models/pole_detector_512_v3/training_summary.txt`).
- Best checkpoint promoted to `models/pole_detector_real.pt` for downstream runs.

### Threshold sweep & deployment
- Ran `src/detection/threshold_sweeper.py` on GPU across confidences 0.05‚Äë0.12 and IoUs 0.45‚Äë0.65 (results in `outputs/analysis/threshold_sweep_20251025_030208.csv`).
- Optimal operating point: **confidence 0.09 / IoU 0.65** (precision 98.71‚ÄØ%, recall 96.80‚ÄØ%, mAP50 99.29‚ÄØ%, mAP50‚Äë95 89.81‚ÄØ%); persisted to `models/exports/detection_thresholds.json`.
- Eval artifacts stored under `outputs/threshold_eval/` for audit.

### Pipeline refresh
- Rehydrated entire stack with `PYTHONPATH=src python run_pilot.py --force` inside the GPU container.
- Latest deployment (21,250 poles) produced **19,547 verified good (92.0‚ÄØ% automation)**, 1 review flag, and 1,702 new/missing detections.
- Exports/dashboards updated in `outputs/exports/*`, `data/processed/ai_detections.csv`, and `data/processed/verified_poles_multi_source.csv`; backend/dashboard restarts inherit the new metrics immediately.

### Next actions
- GPU freed after pipeline verification; kicking off `pole_detector_512_v4` (YOLOv8m, 220 epochs, tighter mosaic 0.20, mixup 0.10, label smoothing 0.02) to probe longer cosine tails and heavier augmentation. Continuous monitoring enabled so the cluster stays saturated through the new 12‚Äëhour window.
